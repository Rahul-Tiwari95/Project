{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import  Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>exceptional service nice daughter priced king ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>beautiful relaxing jw marriott desert ridge ou...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>location location min subway take blommingdale...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pleased nice safe flower market vast array res...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>excellent service excellent location couple mi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14338</th>\n",
       "      <td>14338</td>\n",
       "      <td>madrid perfect location tiny quiet street cent...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14339</th>\n",
       "      <td>14339</td>\n",
       "      <td>excellent florence chosen tripadviser hidden g...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14340</th>\n",
       "      <td>14340</td>\n",
       "      <td>place relax vacation book trip paradisus husba...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14341</th>\n",
       "      <td>14341</td>\n",
       "      <td>week seattle loved minute pacific plaza buy im...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14342</th>\n",
       "      <td>14342</td>\n",
       "      <td>clear internet reservation friday rang hour ad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14343 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                             Review  Rating\n",
       "0          0  exceptional service nice daughter priced king ...       5\n",
       "1          1  beautiful relaxing jw marriott desert ridge ou...       5\n",
       "2          2  location location min subway take blommingdale...       5\n",
       "3          3  pleased nice safe flower market vast array res...       3\n",
       "4          4  excellent service excellent location couple mi...       4\n",
       "...      ...                                                ...     ...\n",
       "14338  14338  madrid perfect location tiny quiet street cent...       5\n",
       "14339  14339  excellent florence chosen tripadviser hidden g...       5\n",
       "14340  14340  place relax vacation book trip paradisus husba...       4\n",
       "14341  14341  week seattle loved minute pacific plaza buy im...       3\n",
       "14342  14342  clear internet reservation friday rang hour ad...       1\n",
       "\n",
       "[14343 rows x 3 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read pickle file\n",
    "train_data=pd.read_pickle(\"train_first_data.pkl\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Word count vs Number of documents')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the word length of reviews\n",
    "word_length= pd.DataFrame({'doc_length': train_data.Review.apply(lambda x: len(x.split()))})\n",
    "\n",
    "# Group the documents based on their number of words (i.e. length)\n",
    "grouped = word_length.groupby('doc_length')\n",
    "\n",
    "indices = grouped.indices\n",
    "word_count = []\n",
    "doc_count = []\n",
    "counter = 0\n",
    "for w,d in indices.items():\n",
    "    word_count.append(w)\n",
    "    doc_count.append(len(d))\n",
    "\n",
    "# Plot the distribution of words vs documents in the corpus\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(word_count, doc_count)\n",
    "plt.xlabel('Word count in document')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.title('Word count vs Number of documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we can see that most of the reviews word length between 100 and 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"word_length\"]=word_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>march wonderful relaxing vacation catalonia ma...</td>\n",
       "      <td>4</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>beautiful return start kind scared read everyo...</td>\n",
       "      <td>4</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>impression maile sky court bit small adequate ...</td>\n",
       "      <td>4</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>definately princess boyfriend night barcelona ...</td>\n",
       "      <td>5</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>high rise high price night october book intern...</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14326</th>\n",
       "      <td>14326</td>\n",
       "      <td>awesome trip whats checked site everyday left ...</td>\n",
       "      <td>5</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14328</th>\n",
       "      <td>14328</td>\n",
       "      <td>star beware smoking room booked package read r...</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14333</th>\n",
       "      <td>14333</td>\n",
       "      <td>ahead husband sister yr daughter witnessed top...</td>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14334</th>\n",
       "      <td>14334</td>\n",
       "      <td>star star location reception pleasant cheerful...</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14340</th>\n",
       "      <td>14340</td>\n",
       "      <td>place relax vacation book trip paradisus husba...</td>\n",
       "      <td>4</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3132 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                             Review  Rating  \\\n",
       "8          8  march wonderful relaxing vacation catalonia ma...       4   \n",
       "14        14  beautiful return start kind scared read everyo...       4   \n",
       "17        17  impression maile sky court bit small adequate ...       4   \n",
       "23        23  definately princess boyfriend night barcelona ...       5   \n",
       "34        34  high rise high price night october book intern...       3   \n",
       "...      ...                                                ...     ...   \n",
       "14326  14326  awesome trip whats checked site everyday left ...       5   \n",
       "14328  14328  star beware smoking room booked package read r...       1   \n",
       "14333  14333  ahead husband sister yr daughter witnessed top...       5   \n",
       "14334  14334  star star location reception pleasant cheerful...       4   \n",
       "14340  14340  place relax vacation book trip paradisus husba...       4   \n",
       "\n",
       "       word_length  \n",
       "8              126  \n",
       "14             240  \n",
       "17             105  \n",
       "23             176  \n",
       "34             104  \n",
       "...            ...  \n",
       "14326          118  \n",
       "14328          113  \n",
       "14333          154  \n",
       "14334          145  \n",
       "14340          178  \n",
       "\n",
       "[3132 rows x 4 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data[\"word_length\"]>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the reviews word length>200\n",
    "train_data.drop(train_data[(train_data.word_length > 100)&(train_data.Rating==5)].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>exceptional service nice daughter priced king ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>beautiful relaxing jw marriott desert ridge ou...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>location location min subway take blommingdale...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pleased nice safe flower market vast array res...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>excellent service excellent location couple mi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14338</th>\n",
       "      <td>14338</td>\n",
       "      <td>madrid perfect location tiny quiet street cent...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14339</th>\n",
       "      <td>14339</td>\n",
       "      <td>excellent florence chosen tripadviser hidden g...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14340</th>\n",
       "      <td>14340</td>\n",
       "      <td>place relax vacation book trip paradisus husba...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14341</th>\n",
       "      <td>14341</td>\n",
       "      <td>week seattle loved minute pacific plaza buy im...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14342</th>\n",
       "      <td>14342</td>\n",
       "      <td>clear internet reservation friday rang hour ad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14343 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                             Review  Rating\n",
       "0          0  exceptional service nice daughter priced king ...       5\n",
       "1          1  beautiful relaxing jw marriott desert ridge ou...       5\n",
       "2          2  location location min subway take blommingdale...       5\n",
       "3          3  pleased nice safe flower market vast array res...       3\n",
       "4          4  excellent service excellent location couple mi...       4\n",
       "...      ...                                                ...     ...\n",
       "14338  14338  madrid perfect location tiny quiet street cent...       5\n",
       "14339  14339  excellent florence chosen tripadviser hidden g...       5\n",
       "14340  14340  place relax vacation book trip paradisus husba...       4\n",
       "14341  14341  week seattle loved minute pacific plaza buy im...       3\n",
       "14342  14342  clear internet reservation friday rang hour ad...       1\n",
       "\n",
       "[14343 rows x 3 columns]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>just superb rendezvous just perfect property s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>better close staten island ferry easy subway  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>enjoyed stay  just come long weekend barcelona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>muse great  muse hotel great  did n t hear noi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>conveniently located morning flight  family st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td>6143</td>\n",
       "      <td>great hotel precruise great hotel arrived earl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>6144</td>\n",
       "      <td>great choice just returned nights grand hotel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>6145</td>\n",
       "      <td>overpriced tiny rooms kowloon past use date ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>6146</td>\n",
       "      <td>ok  agree said positive staff helpful rooms cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>6147</td>\n",
       "      <td>great location husband stayed new orleans     ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6148 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                             Review\n",
       "0        0  just superb rendezvous just perfect property s...\n",
       "1        1  better close staten island ferry easy subway  ...\n",
       "2        2  enjoyed stay  just come long weekend barcelona...\n",
       "3        3  muse great  muse hotel great  did n t hear noi...\n",
       "4        4  conveniently located morning flight  family st...\n",
       "...    ...                                                ...\n",
       "6143  6143  great hotel precruise great hotel arrived earl...\n",
       "6144  6144  great choice just returned nights grand hotel ...\n",
       "6145  6145  overpriced tiny rooms kowloon past use date ne...\n",
       "6146  6146  ok  agree said positive staff helpful rooms cl...\n",
       "6147  6147  great location husband stayed new orleans     ...\n",
       "\n",
       "[6148 rows x 2 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read pickle file for test data\n",
    "test_data=pd.read_pickle(\"test_df.pkl\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rating_count=train_data.groupby(by='Rating').ID.count()\n",
    "rating_count.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Word count vs Number of documents')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the word length of reviews\n",
    "word_length= pd.DataFrame({'doc_length': train_data.Review.apply(lambda x: len(x.split()))})\n",
    "\n",
    "# Group the documents based on their number of words (i.e. length)\n",
    "grouped = word_length.groupby('doc_length')\n",
    "\n",
    "indices = grouped.indices\n",
    "word_count = []\n",
    "doc_count = []\n",
    "counter = 0\n",
    "for w,d in indices.items():\n",
    "    word_count.append(w)\n",
    "    doc_count.append(len(d))\n",
    "\n",
    "# Plot the distribution of words vs documents in the corpus\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(word_count, doc_count)\n",
    "plt.xlabel('Word count in document')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.title('Word count vs Number of documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "1     977\n",
       "2    1248\n",
       "3    1510\n",
       "4    4172\n",
       "5    6436\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(by='Rating').ID.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data for trainung and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_data['Review']\n",
    "y=train_data['Rating']\n",
    "test_X=test_data[\"Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10757,)\n",
      "(3586,)\n",
      "(10757,)\n",
      "(3586,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle stopwords\n",
    "\n",
    "stop= pd.read_pickle('stp_wrds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[1 2 3 4 5], y=7990     5\n",
      "7911     5\n",
      "9532     2\n",
      "5012     5\n",
      "14288    5\n",
      "        ..\n",
      "905      2\n",
      "5192     5\n",
      "12172    5\n",
      "235      5\n",
      "13349    2\n",
      "Name: Rating, Length: 10757, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced' ,np.unique(y_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights={}\n",
    "\n",
    "for index, weight in enumerate(class_weights) :\n",
    "    weights[index]=weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.4468120456905504,\n",
       " 1: 0.6825507614213198,\n",
       " 2: 1.915761353517364,\n",
       " 3: 2.3108485499462943,\n",
       " 4: 2.9230978260869565}"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight={1:0.4468120456905504,\n",
    " 2: 0.6825507614213198,\n",
    " 3: 1.915761353517364,\n",
    " 4: 2.3108485499462943,\n",
    " 5: 2.9230978260869565}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Representation.Bag of word approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", 'ai', 'ca', \"n't\", 'sha', 'wo'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "vect=CountVectorizer(tokenizer=word_tokenize,stop_words=stop, max_df=0.75, lowercase=False, ngram_range=(1,2))\n",
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3284x430784 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 289175 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following four models:\n",
    "\n",
    "Logistic Regression\n",
    "\n",
    "(Multinomial) Naive Bayes\n",
    "\n",
    "Linear Support Vector Machine\n",
    "\n",
    "Xgboost\n",
    "\n",
    "SGD classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_Classifier_result(X, y,X_test,y_test):\n",
    "    NB = MultinomialNB()\n",
    "    NB.fit(X, y)\n",
    "    prediction = NB.predict(X_test)\n",
    "    print(classification_report(prediction, y_test))\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    print(\"NB Classifier result:\")\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LG_Classifier_result(X, y,X_test,y_test):\n",
    "    LG = LogisticRegression()\n",
    "    LG.fit(X,y)\n",
    "    prediction = LG.predict(X_test)\n",
    "    print(classification_report(prediction, y_test))\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    print(\" LG Classifier result:\")\n",
    "     \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_Classifier_result(X, y,X_test,y_test):\n",
    "    SVM = LinearSVC()\n",
    "    SVM.fit(X,y)\n",
    "    prediction = SVM.predict(X_test)\n",
    "    print(classification_report(prediction, y_test))\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    print(\" SVM Classifier result:\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XG_Classifier_result(X, y,X_test,y_test):\n",
    "    XGB = XGBClassifier(objective='multi:softmax', n_estimators=100, learning_rate=0.3, max_depth=4, subsample=0.8, n_iter_no_change=2, verbosity=1)\n",
    "    XGB.fit(X,y)\n",
    "    prediction = XGB.predict(X_test)\n",
    "    print(classification_report(prediction, y_test))\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    print(\" XGB Classifier result:\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_Classifier_result(X, y,X_test,y_test):\n",
    "    SGD = SGDClassifier(max_iter=1000, tol=0.01)\n",
    "    SGD.fit(X,y)\n",
    "    prediction = SGD.predict(X_test)\n",
    "    print(classification_report(prediction, y_test))\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    print(\" SGD Classifier result:\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RF_Classifier_result(X, y,X_test,y_test):\n",
    "    RF = RandomForestClassifier(n_estimators=100, max_depth=100, min_samples_split=10, n_jobs=-1, verbose=0)\n",
    "    RF.fit(X,y)\n",
    "    prediction = RF.predict(X_test)\n",
    "    print(classification_report(prediction, y_test))\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    print(\" RF Classifier result:\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Oversampling Imbalanced Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to improve the performance?\n",
    "\n",
    "Re-sampling Dataset\n",
    "\n",
    "To make our dataset balanced there are two ways to do so:\n",
    "\n",
    "Under-sampling: Remove samples from over-represented classes ; use this if you have huge dataset\n",
    "\n",
    "Over-sampling: Add more samples from under-represented classes; use this if you have small dataset\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random oversampling involves randomly duplicating examples from the minority class and adding them to the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomOverSampler\n",
    "\n",
    "SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13013, 5000) (13013,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:638: FutureWarning: Pass sampling_strategy=minority as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#smote\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE('minority')\n",
    "\n",
    "X_sm, y_sm = smote.fit_sample(X_train_dtm, y_train)\n",
    "print(X_sm.shape, y_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19500, 5000) (19500,)\n"
     ]
    }
   ],
   "source": [
    "#Random oversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_ros, y_ros = ros.fit_sample(X_train_dtm, y_train)\n",
    "print(X_ros.shape, y_ros.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3690, 5000) (3690,)\n"
     ]
    }
   ],
   "source": [
    "#RandomUnderSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "X_rus, y_rus= rus.fit_sample(X_train_dtm, y_train)\n",
    "print(X_rus.shape, y_rus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:638: FutureWarning: Pass sampling_strategy=majority as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#TomekLinks\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks('majority')\n",
    "X_tl, y_tl = tl.fit_sample(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ClusterCentroids\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids()\n",
    "X_cc, y_cc = cc.fit_sample(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:638: FutureWarning: Pass sampling_strategy=auto as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#SMOTETomek\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek('auto')\n",
    "X_smt, y_smt = smt.fit_sample(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasing imbalanced data(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.52      0.57       291\n",
      "           2       0.34      0.33      0.34       330\n",
      "           3       0.28      0.36      0.31       285\n",
      "           4       0.38      0.54      0.44       719\n",
      "           5       0.81      0.65      0.72      1659\n",
      "\n",
      "    accuracy                           0.56      3284\n",
      "   macro avg       0.49      0.48      0.48      3284\n",
      "weighted avg       0.61      0.56      0.57      3284\n",
      "\n",
      "0.5578562728380024\n",
      "(0.5578562728380024, '              precision    recall  f1-score   support\\n\\n           1       0.64      0.52      0.57       291\\n           2       0.34      0.33      0.34       330\\n           3       0.28      0.36      0.31       285\\n           4       0.38      0.54      0.44       719\\n           5       0.81      0.65      0.72      1659\\n\\n    accuracy                           0.56      3284\\n   macro avg       0.49      0.48      0.48      3284\\nweighted avg       0.61      0.56      0.57      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LG Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.57      0.56       227\n",
      "           2       0.31      0.35      0.33       284\n",
      "           3       0.31      0.32      0.32       354\n",
      "           4       0.50      0.51      0.50      1005\n",
      "           5       0.73      0.69      0.71      1414\n",
      "\n",
      "    accuracy                           0.56      3284\n",
      "   macro avg       0.48      0.49      0.48      3284\n",
      "weighted avg       0.57      0.56      0.56      3284\n",
      "\n",
      "0.5572472594397077\n",
      "(0.5572472594397077, '              precision    recall  f1-score   support\\n\\n           1       0.54      0.57      0.56       227\\n           2       0.31      0.35      0.33       284\\n           3       0.31      0.32      0.32       354\\n           4       0.50      0.51      0.50      1005\\n           5       0.73      0.69      0.71      1414\\n\\n    accuracy                           0.56      3284\\n   macro avg       0.48      0.49      0.48      3284\\nweighted avg       0.57      0.56      0.56      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.49      0.45       204\n",
      "           2       0.26      0.29      0.28       282\n",
      "           3       0.28      0.27      0.27       371\n",
      "           4       0.46      0.45      0.45      1047\n",
      "           5       0.68      0.66      0.67      1380\n",
      "\n",
      "    accuracy                           0.51      3284\n",
      "   macro avg       0.42      0.43      0.43      3284\n",
      "weighted avg       0.51      0.51      0.51      3284\n",
      "\n",
      "0.5060901339829477\n",
      "(0.5060901339829477, '              precision    recall  f1-score   support\\n\\n           1       0.42      0.49      0.45       204\\n           2       0.26      0.29      0.28       282\\n           3       0.28      0.27      0.27       371\\n           4       0.46      0.45      0.45      1047\\n           5       0.68      0.66      0.67      1380\\n\\n    accuracy                           0.51      3284\\n   macro avg       0.42      0.43      0.43      3284\\nweighted avg       0.51      0.51      0.51      3284\\n')\n",
      " XGB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.60      0.56       209\n",
      "           2       0.28      0.42      0.34       209\n",
      "           3       0.16      0.39      0.23       153\n",
      "           4       0.54      0.51      0.52      1098\n",
      "           5       0.81      0.67      0.73      1615\n",
      "\n",
      "    accuracy                           0.58      3284\n",
      "   macro avg       0.46      0.52      0.48      3284\n",
      "weighted avg       0.64      0.58      0.60      3284\n",
      "\n",
      "0.580694275274056\n",
      "(0.580694275274056, '              precision    recall  f1-score   support\\n\\n           1       0.52      0.60      0.56       209\\n           2       0.28      0.42      0.34       209\\n           3       0.16      0.39      0.23       153\\n           4       0.54      0.51      0.52      1098\\n           5       0.81      0.67      0.73      1615\\n\\n    accuracy                           0.58      3284\\n   macro avg       0.46      0.52      0.48      3284\\nweighted avg       0.64      0.58      0.60      3284\\n')\n",
      " SGD Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.53      0.53       240\n",
      "           2       0.23      0.36      0.28       205\n",
      "           3       0.26      0.28      0.27       343\n",
      "           4       0.48      0.50      0.49       996\n",
      "           5       0.74      0.65      0.69      1500\n",
      "\n",
      "    accuracy                           0.54      3284\n",
      "   macro avg       0.45      0.46      0.45      3284\n",
      "weighted avg       0.56      0.54      0.55      3284\n",
      "\n",
      "0.5386723507917174\n",
      "(0.5386723507917174, '              precision    recall  f1-score   support\\n\\n           1       0.53      0.53      0.53       240\\n           2       0.23      0.36      0.28       205\\n           3       0.26      0.28      0.27       343\\n           4       0.48      0.50      0.49       996\\n           5       0.74      0.65      0.69      1500\\n\\n    accuracy                           0.54      3284\\n   macro avg       0.45      0.46      0.45      3284\\nweighted avg       0.56      0.54      0.55      3284\\n')\n",
      " RF Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.63      0.53       174\n",
      "           2       0.04      0.39      0.06        28\n",
      "           3       0.00      0.20      0.01         5\n",
      "           4       0.52      0.45      0.48      1186\n",
      "           5       0.87      0.61      0.72      1891\n",
      "\n",
      "    accuracy                           0.55      3284\n",
      "   macro avg       0.38      0.46      0.36      3284\n",
      "weighted avg       0.71      0.55      0.62      3284\n",
      "\n",
      "0.5535931790499391\n",
      "(0.5535931790499391, '              precision    recall  f1-score   support\\n\\n           1       0.46      0.63      0.53       174\\n           2       0.04      0.39      0.06        28\\n           3       0.00      0.20      0.01         5\\n           4       0.52      0.45      0.48      1186\\n           5       0.87      0.61      0.72      1891\\n\\n    accuracy                           0.55      3284\\n   macro avg       0.38      0.46      0.36      3284\\nweighted avg       0.71      0.55      0.62      3284\\n')\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_train_dtm, y_train,X_test_dtm,y_test))\n",
    "print(LG_Classifier_result(X_train_dtm, y_train,X_test_dtm,y_test))\n",
    "print(SVM_Classifier_result(X_train_dtm, y_train,X_test_dtm,y_test))\n",
    "print(XG_Classifier_result(X_train_dtm, y_train,X_test_dtm,y_test))\n",
    "print(SGD_Classifier_result(X_train_dtm, y_train,X_test_dtm,y_test))\n",
    "print(RF_Classifier_result(X_train_dtm, y_train,X_test_dtm,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and evaluating a model using balanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.53      0.57       270\n",
      "           2       0.37      0.33      0.35       353\n",
      "           3       0.28      0.36      0.31       285\n",
      "           4       0.38      0.54      0.44       717\n",
      "           5       0.81      0.65      0.72      1659\n",
      "\n",
      "    accuracy                           0.56      3284\n",
      "   macro avg       0.49      0.48      0.48      3284\n",
      "weighted avg       0.61      0.56      0.57      3284\n",
      "\n",
      "0.5584652862362972\n",
      "(0.5584652862362972, '              precision    recall  f1-score   support\\n\\n           1       0.60      0.53      0.57       270\\n           2       0.37      0.33      0.35       353\\n           3       0.28      0.36      0.31       285\\n           4       0.38      0.54      0.44       717\\n           5       0.81      0.65      0.72      1659\\n\\n    accuracy                           0.56      3284\\n   macro avg       0.49      0.48      0.48      3284\\nweighted avg       0.61      0.56      0.57      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LG Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.45      0.50       309\n",
      "           2       0.32      0.37      0.35       277\n",
      "           3       0.31      0.33      0.32       342\n",
      "           4       0.49      0.52      0.51       988\n",
      "           5       0.72      0.70      0.71      1368\n",
      "\n",
      "    accuracy                           0.55      3284\n",
      "   macro avg       0.48      0.47      0.48      3284\n",
      "weighted avg       0.56      0.55      0.56      3284\n",
      "\n",
      "0.5532886723507917\n",
      "(0.5532886723507917, '              precision    recall  f1-score   support\\n\\n           1       0.58      0.45      0.50       309\\n           2       0.32      0.37      0.35       277\\n           3       0.31      0.33      0.32       342\\n           4       0.49      0.52      0.51       988\\n           5       0.72      0.70      0.71      1368\\n\\n    accuracy                           0.55      3284\\n   macro avg       0.48      0.47      0.48      3284\\nweighted avg       0.56      0.55      0.56      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.46      0.50       287\n",
      "           2       0.25      0.29      0.27       266\n",
      "           3       0.29      0.30      0.30       355\n",
      "           4       0.45      0.46      0.46      1010\n",
      "           5       0.68      0.66      0.67      1366\n",
      "\n",
      "    accuracy                           0.51      3284\n",
      "   macro avg       0.44      0.43      0.44      3284\n",
      "weighted avg       0.52      0.51      0.52      3284\n",
      "\n",
      "0.5121802679658952\n",
      "(0.5121802679658952, '              precision    recall  f1-score   support\\n\\n           1       0.55      0.46      0.50       287\\n           2       0.25      0.29      0.27       266\\n           3       0.29      0.30      0.30       355\\n           4       0.45      0.46      0.46      1010\\n           5       0.68      0.66      0.67      1366\\n\\n    accuracy                           0.51      3284\\n   macro avg       0.44      0.43      0.44      3284\\nweighted avg       0.52      0.51      0.52      3284\\n')\n",
      " XGB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.60      0.56       213\n",
      "           2       0.26      0.41      0.32       196\n",
      "           3       0.17      0.36      0.23       169\n",
      "           4       0.53      0.51      0.52      1070\n",
      "           5       0.82      0.66      0.73      1636\n",
      "\n",
      "    accuracy                           0.58      3284\n",
      "   macro avg       0.46      0.51      0.47      3284\n",
      "weighted avg       0.64      0.58      0.60      3284\n",
      "\n",
      "0.5779537149817296\n",
      "(0.5779537149817296, '              precision    recall  f1-score   support\\n\\n           1       0.53      0.60      0.56       213\\n           2       0.26      0.41      0.32       196\\n           3       0.17      0.36      0.23       169\\n           4       0.53      0.51      0.52      1070\\n           5       0.82      0.66      0.73      1636\\n\\n    accuracy                           0.58      3284\\n   macro avg       0.46      0.51      0.47      3284\\nweighted avg       0.64      0.58      0.60      3284\\n')\n",
      " SGD Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.40      0.45       324\n",
      "           2       0.30      0.33      0.31       281\n",
      "           3       0.21      0.30      0.25       260\n",
      "           4       0.47      0.52      0.49       949\n",
      "           5       0.72      0.65      0.68      1470\n",
      "\n",
      "    accuracy                           0.53      3284\n",
      "   macro avg       0.45      0.44      0.44      3284\n",
      "weighted avg       0.55      0.53      0.54      3284\n",
      "\n",
      "0.5313641900121803\n",
      "(0.5313641900121803, '              precision    recall  f1-score   support\\n\\n           1       0.54      0.40      0.45       324\\n           2       0.30      0.33      0.31       281\\n           3       0.21      0.30      0.25       260\\n           4       0.47      0.52      0.49       949\\n           5       0.72      0.65      0.68      1470\\n\\n    accuracy                           0.53      3284\\n   macro avg       0.45      0.44      0.44      3284\\nweighted avg       0.55      0.53      0.54      3284\\n')\n",
      " RF Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.44      0.50       310\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      1.00      0.01         1\n",
      "           4       0.46      0.48      0.47       977\n",
      "           5       0.89      0.59      0.71      1995\n",
      "\n",
      "    accuracy                           0.55      3284\n",
      "   macro avg       0.38      0.50      0.34      3284\n",
      "weighted avg       0.73      0.55      0.62      3284\n",
      "\n",
      "0.5453714981729598\n",
      "(0.5453714981729598, '              precision    recall  f1-score   support\\n\\n           1       0.57      0.44      0.50       310\\n           2       0.00      0.00      0.00         1\\n           3       0.00      1.00      0.01         1\\n           4       0.46      0.48      0.47       977\\n           5       0.89      0.59      0.71      1995\\n\\n    accuracy                           0.55      3284\\n   macro avg       0.38      0.50      0.34      3284\\nweighted avg       0.73      0.55      0.62      3284\\n')\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_sm, y_sm,X_test_dtm,y_test))\n",
    "print(LG_Classifier_result(X_sm, y_sm,X_test_dtm,y_test))\n",
    "print(SVM_Classifier_result(X_sm, y_sm,X_test_dtm,y_test))\n",
    "print(XG_Classifier_result(X_sm, y_sm,X_test_dtm,y_test))\n",
    "print(SGD_Classifier_result(X_sm, y_sm,X_test_dtm,y_test))\n",
    "print(RF_Classifier_result(X_sm, y_sm,X_test_dtm,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing Random over sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.52      0.55       270\n",
      "           2       0.38      0.33      0.35       368\n",
      "           3       0.34      0.35      0.34       353\n",
      "           4       0.36      0.55      0.43       671\n",
      "           5       0.81      0.66      0.73      1622\n",
      "\n",
      "    accuracy                           0.56      3284\n",
      "   macro avg       0.49      0.48      0.48      3284\n",
      "weighted avg       0.60      0.56      0.57      3284\n",
      "\n",
      "0.5566382460414129\n",
      "(0.5566382460414129, '              precision    recall  f1-score   support\\n\\n           1       0.59      0.52      0.55       270\\n           2       0.38      0.33      0.35       368\\n           3       0.34      0.35      0.34       353\\n           4       0.36      0.55      0.43       671\\n           5       0.81      0.66      0.73      1622\\n\\n    accuracy                           0.56      3284\\n   macro avg       0.49      0.48      0.48      3284\\nweighted avg       0.60      0.56      0.57      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LG Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.57      0.57       244\n",
      "           2       0.34      0.34      0.34       321\n",
      "           3       0.35      0.30      0.32       417\n",
      "           4       0.47      0.51      0.49       959\n",
      "           5       0.71      0.70      0.71      1343\n",
      "\n",
      "    accuracy                           0.55      3284\n",
      "   macro avg       0.49      0.48      0.49      3284\n",
      "weighted avg       0.55      0.55      0.55      3284\n",
      "\n",
      "0.5493300852618758\n",
      "(0.5493300852618758, '              precision    recall  f1-score   support\\n\\n           1       0.58      0.57      0.57       244\\n           2       0.34      0.34      0.34       321\\n           3       0.35      0.30      0.32       417\\n           4       0.47      0.51      0.49       959\\n           5       0.71      0.70      0.71      1343\\n\\n    accuracy                           0.55      3284\\n   macro avg       0.49      0.48      0.49      3284\\nweighted avg       0.55      0.55      0.55      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.49      0.45       205\n",
      "           2       0.28      0.30      0.29       294\n",
      "           3       0.30      0.27      0.28       396\n",
      "           4       0.44      0.45      0.45      1014\n",
      "           5       0.68      0.66      0.67      1375\n",
      "\n",
      "    accuracy                           0.51      3284\n",
      "   macro avg       0.42      0.43      0.43      3284\n",
      "weighted avg       0.51      0.51      0.51      3284\n",
      "\n",
      "0.5054811205846529\n",
      "(0.5054811205846529, '              precision    recall  f1-score   support\\n\\n           1       0.42      0.49      0.45       205\\n           2       0.28      0.30      0.29       294\\n           3       0.30      0.27      0.28       396\\n           4       0.44      0.45      0.45      1014\\n           5       0.68      0.66      0.67      1375\\n\\n    accuracy                           0.51      3284\\n   macro avg       0.42      0.43      0.43      3284\\nweighted avg       0.51      0.51      0.51      3284\\n')\n",
      " XGB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.48      0.54       316\n",
      "           2       0.34      0.35      0.35       304\n",
      "           3       0.33      0.31      0.32       383\n",
      "           4       0.48      0.56      0.52       886\n",
      "           5       0.75      0.71      0.73      1395\n",
      "\n",
      "    accuracy                           0.57      3284\n",
      "   macro avg       0.50      0.48      0.49      3284\n",
      "weighted avg       0.58      0.57      0.57      3284\n",
      "\n",
      "0.567904993909866\n",
      "(0.567904993909866, '              precision    recall  f1-score   support\\n\\n           1       0.63      0.48      0.54       316\\n           2       0.34      0.35      0.35       304\\n           3       0.33      0.31      0.32       383\\n           4       0.48      0.56      0.52       886\\n           5       0.75      0.71      0.73      1395\\n\\n    accuracy                           0.57      3284\\n   macro avg       0.50      0.48      0.49      3284\\nweighted avg       0.58      0.57      0.57      3284\\n')\n",
      " SGD Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.51      0.53       260\n",
      "           2       0.30      0.31      0.30       310\n",
      "           3       0.31      0.28      0.29       407\n",
      "           4       0.39      0.51      0.44       794\n",
      "           5       0.75      0.66      0.70      1513\n",
      "\n",
      "    accuracy                           0.53      3284\n",
      "   macro avg       0.46      0.45      0.45      3284\n",
      "weighted avg       0.55      0.53      0.54      3284\n",
      "\n",
      "0.5292326431181485\n",
      "(0.5292326431181485, '              precision    recall  f1-score   support\\n\\n           1       0.56      0.51      0.53       260\\n           2       0.30      0.31      0.30       310\\n           3       0.31      0.28      0.29       407\\n           4       0.39      0.51      0.44       794\\n           5       0.75      0.66      0.70      1513\\n\\n    accuracy                           0.53      3284\\n   macro avg       0.46      0.45      0.45      3284\\nweighted avg       0.55      0.53      0.54      3284\\n')\n",
      " RF Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.54      0.61       315\n",
      "           2       0.19      0.43      0.26       137\n",
      "           3       0.15      0.46      0.23       123\n",
      "           4       0.47      0.54      0.50       905\n",
      "           5       0.86      0.63      0.73      1804\n",
      "\n",
      "    accuracy                           0.58      3284\n",
      "   macro avg       0.48      0.52      0.47      3284\n",
      "weighted avg       0.68      0.58      0.62      3284\n",
      "\n",
      "0.5828258221680876\n",
      "(0.5828258221680876, '              precision    recall  f1-score   support\\n\\n           1       0.71      0.54      0.61       315\\n           2       0.19      0.43      0.26       137\\n           3       0.15      0.46      0.23       123\\n           4       0.47      0.54      0.50       905\\n           5       0.86      0.63      0.73      1804\\n\\n    accuracy                           0.58      3284\\n   macro avg       0.48      0.52      0.47      3284\\nweighted avg       0.68      0.58      0.62      3284\\n')\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_ros, y_ros,X_test_dtm,y_test))\n",
    "print(LG_Classifier_result(X_ros, y_ros,X_test_dtm,y_test))\n",
    "print(SVM_Classifier_result(X_ros, y_ros,X_test_dtm,y_test))\n",
    "print(XG_Classifier_result(X_ros, y_ros,X_test_dtm,y_test))\n",
    "print(SGD_Classifier_result(X_ros, y_ros,X_test_dtm,y_test))\n",
    "print(RF_Classifier_result(X_ros, y_ros,X_test_dtm,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# passing Random under sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.50      0.58       327\n",
      "           2       0.35      0.29      0.32       370\n",
      "           3       0.37      0.29      0.32       468\n",
      "           4       0.30      0.51      0.38       614\n",
      "           5       0.75      0.66      0.70      1505\n",
      "\n",
      "    accuracy                           0.52      3284\n",
      "   macro avg       0.49      0.45      0.46      3284\n",
      "weighted avg       0.56      0.52      0.53      3284\n",
      "\n",
      "0.5225334957369062\n",
      "(0.5225334957369062, '              precision    recall  f1-score   support\\n\\n           1       0.68      0.50      0.58       327\\n           2       0.35      0.29      0.32       370\\n           3       0.37      0.29      0.32       468\\n           4       0.30      0.51      0.38       614\\n           5       0.75      0.66      0.70      1505\\n\\n    accuracy                           0.52      3284\\n   macro avg       0.49      0.45      0.46      3284\\nweighted avg       0.56      0.52      0.53      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LG Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.51      0.56       293\n",
      "           2       0.36      0.30      0.33       371\n",
      "           3       0.39      0.27      0.32       538\n",
      "           4       0.43      0.51      0.47       868\n",
      "           5       0.66      0.72      0.69      1214\n",
      "\n",
      "    accuracy                           0.53      3284\n",
      "   macro avg       0.49      0.46      0.47      3284\n",
      "weighted avg       0.52      0.53      0.52      3284\n",
      "\n",
      "0.52557856272838\n",
      "(0.52557856272838, '              precision    recall  f1-score   support\\n\\n           1       0.62      0.51      0.56       293\\n           2       0.36      0.30      0.33       371\\n           3       0.39      0.27      0.32       538\\n           4       0.43      0.51      0.47       868\\n           5       0.66      0.72      0.69      1214\\n\\n    accuracy                           0.53      3284\\n   macro avg       0.49      0.46      0.47      3284\\nweighted avg       0.52      0.53      0.52      3284\\n')\n",
      " SVM Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.46      0.51       298\n",
      "           2       0.32      0.27      0.30       371\n",
      "           3       0.37      0.25      0.30       554\n",
      "           4       0.40      0.47      0.43       879\n",
      "           5       0.61      0.68      0.64      1182\n",
      "\n",
      "    accuracy                           0.49      3284\n",
      "   macro avg       0.46      0.43      0.44      3284\n",
      "weighted avg       0.48      0.49      0.48      3284\n",
      "\n",
      "0.48629719853836784\n",
      "(0.48629719853836784, '              precision    recall  f1-score   support\\n\\n           1       0.57      0.46      0.51       298\\n           2       0.32      0.27      0.30       371\\n           3       0.37      0.25      0.30       554\\n           4       0.40      0.47      0.43       879\\n           5       0.61      0.68      0.64      1182\\n\\n    accuracy                           0.49      3284\\n   macro avg       0.46      0.43      0.44      3284\\nweighted avg       0.48      0.49      0.48      3284\\n')\n",
      " XGB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.48      0.56       335\n",
      "           2       0.41      0.34      0.37       383\n",
      "           3       0.39      0.27      0.32       528\n",
      "           4       0.38      0.51      0.44       787\n",
      "           5       0.68      0.72      0.70      1251\n",
      "\n",
      "    accuracy                           0.53      3284\n",
      "   macro avg       0.51      0.46      0.48      3284\n",
      "weighted avg       0.53      0.53      0.52      3284\n",
      "\n",
      "0.5274056029232643\n",
      "(0.5274056029232643, '              precision    recall  f1-score   support\\n\\n           1       0.68      0.48      0.56       335\\n           2       0.41      0.34      0.37       383\\n           3       0.39      0.27      0.32       528\\n           4       0.38      0.51      0.44       787\\n           5       0.68      0.72      0.70      1251\\n\\n    accuracy                           0.53      3284\\n   macro avg       0.51      0.46      0.48      3284\\nweighted avg       0.53      0.53      0.52      3284\\n')\n",
      " SGD Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.51      0.53       258\n",
      "           2       0.33      0.27      0.30       386\n",
      "           3       0.40      0.23      0.29       629\n",
      "           4       0.40      0.46      0.43       905\n",
      "           5       0.59      0.71      0.65      1106\n",
      "\n",
      "    accuracy                           0.48      3284\n",
      "   macro avg       0.45      0.44      0.44      3284\n",
      "weighted avg       0.47      0.48      0.47      3284\n",
      "\n",
      "0.4826431181485993\n",
      "(0.4826431181485993, '              precision    recall  f1-score   support\\n\\n           1       0.55      0.51      0.53       258\\n           2       0.33      0.27      0.30       386\\n           3       0.40      0.23      0.29       629\\n           4       0.40      0.46      0.43       905\\n           5       0.59      0.71      0.65      1106\\n\\n    accuracy                           0.48      3284\\n   macro avg       0.45      0.44      0.44      3284\\nweighted avg       0.47      0.48      0.47      3284\\n')\n",
      " RF Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.41      0.54       465\n",
      "           2       0.23      0.29      0.25       247\n",
      "           3       0.35      0.28      0.32       453\n",
      "           4       0.30      0.55      0.39       566\n",
      "           5       0.78      0.66      0.72      1553\n",
      "\n",
      "    accuracy                           0.53      3284\n",
      "   macro avg       0.49      0.44      0.44      3284\n",
      "weighted avg       0.60      0.53      0.55      3284\n",
      "\n",
      "0.5289281364190013\n",
      "(0.5289281364190013, '              precision    recall  f1-score   support\\n\\n           1       0.80      0.41      0.54       465\\n           2       0.23      0.29      0.25       247\\n           3       0.35      0.28      0.32       453\\n           4       0.30      0.55      0.39       566\\n           5       0.78      0.66      0.72      1553\\n\\n    accuracy                           0.53      3284\\n   macro avg       0.49      0.44      0.44      3284\\nweighted avg       0.60      0.53      0.55      3284\\n')\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_rus, y_rus,X_test_dtm,y_test))\n",
    "print(LG_Classifier_result(X_rus, y_rus,X_test_dtm,y_test))\n",
    "print(SVM_Classifier_result(X_rus, y_rus,X_test_dtm,y_test))\n",
    "print(XG_Classifier_result(X_rus, y_rus,X_test_dtm,y_test))\n",
    "print(SGD_Classifier_result(X_rus, y_rus,X_test_dtm,y_test))\n",
    "print(RF_Classifier_result(X_rus, y_rus,X_test_dtm,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TomekLinks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.52      0.57       291\n",
      "           2       0.34      0.33      0.34       330\n",
      "           3       0.28      0.36      0.31       285\n",
      "           4       0.38      0.54      0.44       720\n",
      "           5       0.81      0.65      0.72      1658\n",
      "\n",
      "    accuracy                           0.56      3284\n",
      "   macro avg       0.49      0.48      0.48      3284\n",
      "weighted avg       0.61      0.56      0.57      3284\n",
      "\n",
      "0.557551766138855\n",
      "(0.557551766138855, '              precision    recall  f1-score   support\\n\\n           1       0.64      0.52      0.57       291\\n           2       0.34      0.33      0.34       330\\n           3       0.28      0.36      0.31       285\\n           4       0.38      0.54      0.44       720\\n           5       0.81      0.65      0.72      1658\\n\\n    accuracy                           0.56      3284\\n   macro avg       0.49      0.48      0.48      3284\\nweighted avg       0.61      0.56      0.57      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LG Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.57      0.56       229\n",
      "           2       0.31      0.35      0.32       278\n",
      "           3       0.31      0.32      0.32       354\n",
      "           4       0.50      0.51      0.50      1020\n",
      "           5       0.73      0.69      0.71      1403\n",
      "\n",
      "    accuracy                           0.56      3284\n",
      "   macro avg       0.48      0.49      0.48      3284\n",
      "weighted avg       0.56      0.56      0.56      3284\n",
      "\n",
      "0.5554202192448234\n",
      "(0.5554202192448234, '              precision    recall  f1-score   support\\n\\n           1       0.54      0.57      0.56       229\\n           2       0.31      0.35      0.32       278\\n           3       0.31      0.32      0.32       354\\n           4       0.50      0.51      0.50      1020\\n           5       0.73      0.69      0.71      1403\\n\\n    accuracy                           0.56      3284\\n   macro avg       0.48      0.49      0.48      3284\\nweighted avg       0.56      0.56      0.56      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.49      0.46       207\n",
      "           2       0.26      0.30      0.28       275\n",
      "           3       0.28      0.27      0.27       371\n",
      "           4       0.46      0.45      0.46      1047\n",
      "           5       0.68      0.66      0.67      1384\n",
      "\n",
      "    accuracy                           0.51      3284\n",
      "   macro avg       0.42      0.44      0.43      3284\n",
      "weighted avg       0.51      0.51      0.51      3284\n",
      "\n",
      "0.5079171741778319\n",
      "(0.5079171741778319, '              precision    recall  f1-score   support\\n\\n           1       0.43      0.49      0.46       207\\n           2       0.26      0.30      0.28       275\\n           3       0.28      0.27      0.27       371\\n           4       0.46      0.45      0.46      1047\\n           5       0.68      0.66      0.67      1384\\n\\n    accuracy                           0.51      3284\\n   macro avg       0.42      0.44      0.43      3284\\nweighted avg       0.51      0.51      0.51      3284\\n')\n",
      " XGB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.64      0.58       200\n",
      "           2       0.29      0.43      0.35       213\n",
      "           3       0.16      0.36      0.22       159\n",
      "           4       0.54      0.52      0.53      1081\n",
      "           5       0.81      0.66      0.73      1631\n",
      "\n",
      "    accuracy                           0.59      3284\n",
      "   macro avg       0.47      0.52      0.48      3284\n",
      "weighted avg       0.64      0.59      0.61      3284\n",
      "\n",
      "0.5852618757612668\n",
      "(0.5852618757612668, '              precision    recall  f1-score   support\\n\\n           1       0.53      0.64      0.58       200\\n           2       0.29      0.43      0.35       213\\n           3       0.16      0.36      0.22       159\\n           4       0.54      0.52      0.53      1081\\n           5       0.81      0.66      0.73      1631\\n\\n    accuracy                           0.59      3284\\n   macro avg       0.47      0.52      0.48      3284\\nweighted avg       0.64      0.59      0.61      3284\\n')\n",
      " SGD Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.56      0.53       209\n",
      "           2       0.24      0.32      0.28       237\n",
      "           3       0.27      0.28      0.27       359\n",
      "           4       0.47      0.49      0.48       993\n",
      "           5       0.72      0.64      0.68      1486\n",
      "\n",
      "    accuracy                           0.53      3284\n",
      "   macro avg       0.44      0.46      0.45      3284\n",
      "weighted avg       0.54      0.53      0.53      3284\n",
      "\n",
      "0.5261875761266748\n",
      "(0.5261875761266748, '              precision    recall  f1-score   support\\n\\n           1       0.49      0.56      0.53       209\\n           2       0.24      0.32      0.28       237\\n           3       0.27      0.28      0.27       359\\n           4       0.47      0.49      0.48       993\\n           5       0.72      0.64      0.68      1486\\n\\n    accuracy                           0.53      3284\\n   macro avg       0.44      0.46      0.45      3284\\nweighted avg       0.54      0.53      0.53      3284\\n')\n",
      " RF Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.67      0.55       166\n",
      "           2       0.04      0.48      0.08        29\n",
      "           3       0.00      0.17      0.01         6\n",
      "           4       0.53      0.46      0.49      1198\n",
      "           5       0.88      0.62      0.73      1885\n",
      "\n",
      "    accuracy                           0.56      3284\n",
      "   macro avg       0.38      0.48      0.37      3284\n",
      "weighted avg       0.72      0.56      0.62      3284\n",
      "\n",
      "0.5596833130328868\n",
      "(0.5596833130328868, '              precision    recall  f1-score   support\\n\\n           1       0.46      0.67      0.55       166\\n           2       0.04      0.48      0.08        29\\n           3       0.00      0.17      0.01         6\\n           4       0.53      0.46      0.49      1198\\n           5       0.88      0.62      0.73      1885\\n\\n    accuracy                           0.56      3284\\n   macro avg       0.38      0.48      0.37      3284\\nweighted avg       0.72      0.56      0.62      3284\\n')\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_tl,y_tl,X_test_dtm,y_test))\n",
    "print(LG_Classifier_result(X_tl,y_tl,X_test_dtm,y_test))\n",
    "print(SVM_Classifier_result(X_tl,y_tl,X_test_dtm,y_test))\n",
    "print(XG_Classifier_result(X_tl,y_tl,X_test_dtm,y_test))\n",
    "print(SGD_Classifier_result(X_tl,y_tl,X_test_dtm,y_test))\n",
    "print(RF_Classifier_result(X_tl,y_tl,X_test_dtm,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTETomek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.55      0.58       265\n",
      "           2       0.39      0.35      0.37       350\n",
      "           3       0.31      0.36      0.33       321\n",
      "           4       0.37      0.54      0.44       722\n",
      "           5       0.81      0.66      0.73      1626\n",
      "\n",
      "    accuracy                           0.56      3284\n",
      "   macro avg       0.50      0.49      0.49      3284\n",
      "weighted avg       0.60      0.56      0.57      3284\n",
      "\n",
      "0.5605968331303288\n",
      "(0.5605968331303288, '              precision    recall  f1-score   support\\n\\n           1       0.61      0.55      0.58       265\\n           2       0.39      0.35      0.37       350\\n           3       0.31      0.36      0.33       321\\n           4       0.37      0.54      0.44       722\\n           5       0.81      0.66      0.73      1626\\n\\n    accuracy                           0.56      3284\\n   macro avg       0.50      0.49      0.49      3284\\nweighted avg       0.60      0.56      0.57      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LG Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.55      0.57       258\n",
      "           2       0.33      0.32      0.33       331\n",
      "           3       0.33      0.30      0.31       397\n",
      "           4       0.49      0.50      0.49      1006\n",
      "           5       0.68      0.70      0.69      1292\n",
      "\n",
      "    accuracy                           0.54      3284\n",
      "   macro avg       0.48      0.47      0.48      3284\n",
      "weighted avg       0.54      0.54      0.54      3284\n",
      "\n",
      "0.5414129110840439\n",
      "(0.5414129110840439, '              precision    recall  f1-score   support\\n\\n           1       0.59      0.55      0.57       258\\n           2       0.33      0.32      0.33       331\\n           3       0.33      0.30      0.31       397\\n           4       0.49      0.50      0.49      1006\\n           5       0.68      0.70      0.69      1292\\n\\n    accuracy                           0.54      3284\\n   macro avg       0.48      0.47      0.48      3284\\nweighted avg       0.54      0.54      0.54      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.51      0.51       242\n",
      "           2       0.27      0.26      0.27       321\n",
      "           3       0.30      0.25      0.28       440\n",
      "           4       0.44      0.46      0.45       986\n",
      "           5       0.65      0.67      0.66      1295\n",
      "\n",
      "    accuracy                           0.50      3284\n",
      "   macro avg       0.44      0.43      0.43      3284\n",
      "weighted avg       0.49      0.50      0.50      3284\n",
      "\n",
      "0.4993909866017052\n",
      "(0.4993909866017052, '              precision    recall  f1-score   support\\n\\n           1       0.51      0.51      0.51       242\\n           2       0.27      0.26      0.27       321\\n           3       0.30      0.25      0.28       440\\n           4       0.44      0.46      0.45       986\\n           5       0.65      0.67      0.66      1295\\n\\n    accuracy                           0.50      3284\\n   macro avg       0.44      0.43      0.43      3284\\nweighted avg       0.49      0.50      0.50      3284\\n')\n",
      " XGB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.60      0.57       214\n",
      "           2       0.27      0.40      0.32       210\n",
      "           3       0.14      0.36      0.21       148\n",
      "           4       0.55      0.51      0.53      1104\n",
      "           5       0.81      0.67      0.73      1608\n",
      "\n",
      "    accuracy                           0.58      3284\n",
      "   macro avg       0.46      0.51      0.47      3284\n",
      "weighted avg       0.64      0.58      0.60      3284\n",
      "\n",
      "0.5809987819732034\n",
      "(0.5809987819732034, '              precision    recall  f1-score   support\\n\\n           1       0.54      0.60      0.57       214\\n           2       0.27      0.40      0.32       210\\n           3       0.14      0.36      0.21       148\\n           4       0.55      0.51      0.53      1104\\n           5       0.81      0.67      0.73      1608\\n\\n    accuracy                           0.58      3284\\n   macro avg       0.46      0.51      0.47      3284\\nweighted avg       0.64      0.58      0.60      3284\\n')\n",
      " SGD Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.51      0.52       250\n",
      "           2       0.32      0.29      0.30       349\n",
      "           3       0.34      0.30      0.32       419\n",
      "           4       0.45      0.51      0.48       910\n",
      "           5       0.70      0.68      0.69      1356\n",
      "\n",
      "    accuracy                           0.53      3284\n",
      "   macro avg       0.47      0.46      0.46      3284\n",
      "weighted avg       0.53      0.53      0.53      3284\n",
      "\n",
      "0.5304506699147381\n",
      "(0.5304506699147381, '              precision    recall  f1-score   support\\n\\n           1       0.54      0.51      0.52       250\\n           2       0.32      0.29      0.30       349\\n           3       0.34      0.30      0.32       419\\n           4       0.45      0.51      0.48       910\\n           5       0.70      0.68      0.69      1356\\n\\n    accuracy                           0.53      3284\\n   macro avg       0.47      0.46      0.46      3284\\nweighted avg       0.53      0.53      0.53      3284\\n')\n",
      " RF Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.56      0.52       206\n",
      "           2       0.17      0.34      0.23       161\n",
      "           3       0.13      0.32      0.18       146\n",
      "           4       0.52      0.48      0.50      1114\n",
      "           5       0.81      0.65      0.72      1657\n",
      "\n",
      "    accuracy                           0.56      3284\n",
      "   macro avg       0.42      0.47      0.43      3284\n",
      "weighted avg       0.63      0.56      0.58      3284\n",
      "\n",
      "0.5566382460414129\n",
      "(0.5566382460414129, '              precision    recall  f1-score   support\\n\\n           1       0.49      0.56      0.52       206\\n           2       0.17      0.34      0.23       161\\n           3       0.13      0.32      0.18       146\\n           4       0.52      0.48      0.50      1114\\n           5       0.81      0.65      0.72      1657\\n\\n    accuracy                           0.56      3284\\n   macro avg       0.42      0.47      0.43      3284\\nweighted avg       0.63      0.56      0.58      3284\\n')\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_smt,y_smt,X_test_dtm,y_test))\n",
    "print(LG_Classifier_result(X_smt,y_smt,X_test_dtm,y_test))\n",
    "print(SVM_Classifier_result(X_smt,y_smt,X_test_dtm,y_test))\n",
    "print(XG_Classifier_result(X_smt,y_smt,X_test_dtm,y_test))\n",
    "print(SGD_Classifier_result(X_smt,y_smt,X_test_dtm,y_test))\n",
    "print(RF_Classifier_result(X_smt,y_smt,X_test_dtm,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=word_tokenize,stop_words=stop, lowercase=False, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", 'ai', 'ca', \"n't\", 'sha', 'wo'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "#transforming test data and train data in to a document term matrix\n",
    "X_Train_Dtm=vectorizer.fit_transform(X_train)\n",
    "X_Test_Dtm=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10757, 515625), (10757,), (3586, 515625), (3586,))"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train_Dtm.shape, y_train.shape,X_Test_Dtm.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model : Passing imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       1.00      0.45      0.62      3586\n",
      "\n",
      "    accuracy                           0.45      3586\n",
      "   macro avg       0.20      0.09      0.12      3586\n",
      "weighted avg       1.00      0.45      0.62      3586\n",
      "\n",
      "0.4520356943669827\n",
      "NB Classifier result:\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.76      0.57       144\n",
      "           2       0.17      0.40      0.24       135\n",
      "           3       0.06      0.34      0.10        65\n",
      "           4       0.49      0.43      0.46      1166\n",
      "           5       0.86      0.67      0.75      2076\n",
      "\n",
      "    accuracy                           0.58      3586\n",
      "   macro avg       0.41      0.52      0.42      3586\n",
      "weighted avg       0.68      0.58      0.62      3586\n",
      "\n",
      "0.5786391522587842\n",
      " LG Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.59      0.59       242\n",
      "           2       0.23      0.42      0.29       172\n",
      "           3       0.16      0.39      0.22       155\n",
      "           4       0.50      0.47      0.49      1085\n",
      "           5       0.83      0.69      0.75      1932\n",
      "\n",
      "    accuracy                           0.59      3586\n",
      "   macro avg       0.46      0.51      0.47      3586\n",
      "weighted avg       0.65      0.59      0.62      3586\n",
      "\n",
      "0.5925822643614055\n",
      " SVM Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.63      0.57       198\n",
      "           2       0.22      0.40      0.28       177\n",
      "           3       0.24      0.41      0.30       230\n",
      "           4       0.50      0.45      0.47      1155\n",
      "           5       0.78      0.69      0.73      1826\n",
      "\n",
      "    accuracy                           0.57      3586\n",
      "   macro avg       0.45      0.51      0.47      3586\n",
      "weighted avg       0.61      0.57      0.59      3586\n",
      "\n",
      "0.5747350808700502\n",
      " XGB Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.59      0.64       285\n",
      "           2       0.17      0.45      0.25       122\n",
      "           3       0.13      0.42      0.20       121\n",
      "           4       0.43      0.46      0.44       951\n",
      "           5       0.87      0.67      0.76      2107\n",
      "\n",
      "    accuracy                           0.59      3586\n",
      "   macro avg       0.46      0.52      0.46      3586\n",
      "weighted avg       0.69      0.59      0.63      3586\n",
      "\n",
      "0.5914668153931958\n",
      " SGD Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.11      0.84      0.20        32\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.11      0.35      0.17       326\n",
      "           5       0.98      0.49      0.65      3224\n",
      "\n",
      "    accuracy                           0.48      3586\n",
      "   macro avg       0.24      0.34      0.20      3586\n",
      "weighted avg       0.89      0.48      0.60      3586\n",
      "\n",
      "0.4807585052983826\n",
      " RF Classifier result:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-370-0618859b0aab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXG_Classifier_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Train_Dtm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_Test_Dtm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSGD_Classifier_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Train_Dtm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_Test_Dtm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRF_Classifier_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Train_Dtm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_Test_Dtm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-369-ef7bd6cf2595>\u001b[0m in \u001b[0;36mRF_Classifier_result\u001b[1;34m(X, y, X_test, y_test)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" RF Classifier result:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'report' is not defined"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_Train_Dtm, y_train,X_Test_Dtm,y_test))\n",
    "print(LG_Classifier_result(X_Train_Dtm, y_train,X_Test_Dtm,y_test)) \n",
    "print(SVM_Classifier_result(X_Train_Dtm, y_train,X_Test_Dtm,y_test))\n",
    "print(XG_Classifier_result(X_Train_Dtm, y_train,X_Test_Dtm,y_test))\n",
    "print(SGD_Classifier_result(X_Train_Dtm, y_train,X_Test_Dtm,y_test))\n",
    "print(RF_Classifier_result(X_Train_Dtm, y_train,X_Test_Dtm,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model : Passing balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:638: FutureWarning: Pass sampling_strategy=minority as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14836, 515625) (14836,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE('minority')\n",
    "\n",
    "X_sm_t, y_sm_t = smote.fit_sample(X_Train_Dtm, y_train)\n",
    "print(X_sm_t.shape, y_sm_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_ros_t, y_ros_t = ros.fit_sample(X_Train_Dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:638: FutureWarning: Pass sampling_strategy=majority as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10334, 515625), (10334,))"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks('majority')\n",
    "X_tl_t, y_tl_t = tl.fit_sample(X_Train_Dtm, y_train)\n",
    "X_tl_t.shape,y_tl_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:638: FutureWarning: Pass sampling_strategy=auto as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek('auto')\n",
    "X_smt_t, y_smt_t = smt.fit_sample(X_Train_Dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.33      0.49       724\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.98      0.55      0.71      2862\n",
      "\n",
      "    accuracy                           0.51      3586\n",
      "   macro avg       0.39      0.18      0.24      3586\n",
      "weighted avg       0.98      0.51      0.66      3586\n",
      "\n",
      "0.507250418293363\n",
      "NB Classifier result:\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.46      0.60       454\n",
      "           2       0.01      0.67      0.01         3\n",
      "           3       0.04      0.37      0.07        41\n",
      "           4       0.49      0.46      0.47      1085\n",
      "           5       0.85      0.69      0.76      2003\n",
      "\n",
      "    accuracy                           0.59      3586\n",
      "   macro avg       0.45      0.53      0.38      3586\n",
      "weighted avg       0.73      0.59      0.64      3586\n",
      "\n",
      "0.5850529838259899\n",
      " LG Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.56      0.65       328\n",
      "           2       0.17      0.50      0.25       105\n",
      "           3       0.16      0.41      0.23       145\n",
      "           4       0.50      0.47      0.49      1085\n",
      "           5       0.82      0.69      0.75      1923\n",
      "\n",
      "    accuracy                           0.60      3586\n",
      "   macro avg       0.48      0.53      0.47      3586\n",
      "weighted avg       0.68      0.60      0.63      3586\n",
      "\n",
      "0.5989960959286112\n",
      " SVM Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.60      0.55       208\n",
      "           2       0.25      0.40      0.31       199\n",
      "           3       0.20      0.35      0.26       228\n",
      "           4       0.50      0.45      0.47      1130\n",
      "           5       0.77      0.69      0.73      1821\n",
      "\n",
      "    accuracy                           0.57      3586\n",
      "   macro avg       0.45      0.50      0.46      3586\n",
      "weighted avg       0.61      0.57      0.58      3586\n",
      "\n",
      "0.569994422755159\n",
      " XGB Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.46      0.60       444\n",
      "           2       0.07      0.49      0.12        45\n",
      "           3       0.10      0.45      0.17        89\n",
      "           4       0.36      0.47      0.41       788\n",
      "           5       0.90      0.65      0.76      2220\n",
      "\n",
      "    accuracy                           0.58      3586\n",
      "   macro avg       0.46      0.50      0.41      3586\n",
      "weighted avg       0.74      0.58      0.64      3586\n",
      "\n",
      "0.5828220858895705\n",
      " SGD Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.63      0.53       176\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.04      0.39      0.07       105\n",
      "           5       0.99      0.49      0.65      3305\n",
      "\n",
      "    accuracy                           0.49      3586\n",
      "   macro avg       0.30      0.30      0.25      3586\n",
      "weighted avg       0.94      0.49      0.63      3586\n",
      "\n",
      "0.4894032348020078\n",
      " RF Classifier result:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-375-fef07b45ab17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXG_Classifier_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_sm_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_sm_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_Test_Dtm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSGD_Classifier_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_sm_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_sm_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_Test_Dtm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRF_Classifier_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_sm_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_sm_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_Test_Dtm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-369-ef7bd6cf2595>\u001b[0m in \u001b[0;36mRF_Classifier_result\u001b[1;34m(X, y, X_test, y_test)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" RF Classifier result:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'report' is not defined"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_sm_t, y_sm_t,X_Test_Dtm,y_test))\n",
    "print(LG_Classifier_result(X_sm_t, y_sm_t,X_Test_Dtm,y_test))\n",
    "print(SVM_Classifier_result(X_sm_t, y_sm_t,X_Test_Dtm,y_test))\n",
    "print(XG_Classifier_result(X_sm_t, y_sm_t,X_Test_Dtm,y_test))\n",
    "print(SGD_Classifier_result(X_sm_t, y_sm_t,X_Test_Dtm,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.60      0.54       192\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.03      0.29      0.05        89\n",
      "           5       0.99      0.48      0.65      3305\n",
      "\n",
      "    accuracy                           0.49      3586\n",
      "   macro avg       0.30      0.28      0.25      3586\n",
      "weighted avg       0.94      0.49      0.63      3586\n",
      "\n",
      "0.4860568878973787\n",
      " RF Classifier result:\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(RF_Classifier_result(X_sm_t, y_sm_t,X_Test_Dtm,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight={1: 0.4468120456905504, 2: 0.6825507614213198,\n",
       "                  3: 1.915761353517364, 4: 2.3108485499462943,\n",
       "                  5: 2.9230978260869565},\n",
       "    kernel='linear')"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVC include parameter class_weight\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(C=10, gamma=1,kernel='linear',class_weight=weight) \n",
    "model.fit(X_sm_t, y_sm_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_Test_Dtm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5984383714445064"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.00000000e-05, 8.48342898e-05, 7.19685673e-04, 6.10540230e-03,\n",
       "       5.17947468e-02, 4.39397056e-01, 3.72759372e+00, 3.16227766e+01,\n",
       "       2.68269580e+02, 2.27584593e+03, 1.93069773e+04, 1.63789371e+05,\n",
       "       1.38949549e+06, 1.17876863e+07, 1.00000000e+08])})"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "  \n",
    "# Creating the hyperparameter grid \n",
    "c_space = np.logspace(-5, 8, 15) \n",
    "param_grid = {'C': c_space} \n",
    "  \n",
    "# Instantiating logistic regression classifier \n",
    "logreg = LogisticRegression() \n",
    "  \n",
    "# Instantiating the GridSearchCV object \n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv = 5) \n",
    "  \n",
    "logreg_cv.fit(X_sm_t, y_sm_t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7218265475486416"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 11787686.347935867}"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=11787686.347935867,\n",
       "                   class_weight={1: 0.4468120456905504, 2: 0.6825507614213198,\n",
       "                                 3: 1.915761353517364, 4: 2.3108485499462943,\n",
       "                                 5: 2.9230978260869565})"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression(C=11787686.347935867,class_weight=weight)\n",
    "lr.fit(X_sm_t, y_sm_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 5, ..., 5, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=lr.predict(X_Test_Dtm)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6017847183491355"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       just superb rendezvous just perfect property s...\n",
       "1       better close staten island ferry easy subway  ...\n",
       "2       enjoyed stay  just come long weekend barcelona...\n",
       "3       muse great  muse hotel great  did n t hear noi...\n",
       "4       conveniently located morning flight  family st...\n",
       "                              ...                        \n",
       "6143    great hotel precruise great hotel arrived earl...\n",
       "6144    great choice just returned nights grand hotel ...\n",
       "6145    overpriced tiny rooms kowloon past use date ne...\n",
       "6146    ok  agree said positive staff helpful rooms cl...\n",
       "6147    great location husband stayed new orleans     ...\n",
       "Name: Review, Length: 6148, dtype: object"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have already a test data..we can apply test_X data to check the accuaracy of a predicted model\n",
    "test_X=test_data[\"Review\"]\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6148x430784 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 506519 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_datas = vectorizer.transform(test_X)\n",
    "X_test_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 4 ... 3 4 4]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test_datas)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NB_Classifier_result())\n",
    "print(LG_Classifier_result())\n",
    "print(SVM_Classifier_result())\n",
    "print(XG_Classifier_result())\n",
    "print(SGD_Classifier_result())\n",
    "print(RF_Classifier_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td>6143</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>6144</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>6145</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>6146</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>6147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6148 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Rating\n",
       "0        0       5\n",
       "1        1       2\n",
       "2        2       4\n",
       "3        3       5\n",
       "4        4       4\n",
       "...    ...     ...\n",
       "6143  6143       5\n",
       "6144  6144       5\n",
       "6145  6145       3\n",
       "6146  6146       4\n",
       "6147  6147       3\n",
       "\n",
       "[6148 rows x 2 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload sample submission file\n",
    "sample_df=pd.read_csv(\"sample submission (2).csv\")\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding predicted Item_Outlet_Sales in to sample_df\n",
    "pred=pd.DataFrame(y_pred)\n",
    "data=pd.concat([sample_df[\"ID\"],pred],axis=1)\n",
    "\n",
    "data.columns=[\"ID\",\"Rating\"]\n",
    "data.to_csv(\"sample submission (2).csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
